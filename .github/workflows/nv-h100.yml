name: nv-h100

on:
  push:
    branches:
      - 'staging**'
    paths-ignore:
      - 'docs/**'
      - 'blogs/**'
  pull_request:
    paths-ignore:
      - 'docs/**'
      - 'blogs/**'
  schedule:
    - cron: "0 0 * * *"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  unit-tests:
    runs-on: [self-hosted, nvidia, h100]
    container:
      image: nvcr.io/nvidia/pytorch:23.03-py3
      ports:
        - 80
      options: --gpus all

    steps:
      - uses: actions/checkout@v3

      - name: Install dependencies
        run: |
          apt install -y ninja-build
          python -c "import torch; print('torch:', torch.__version__, torch)"
          python -c "import torch; print('CUDA available:', torch.cuda.is_available())"

      - name: Install transformers
        run: |
          git clone https://github.com/huggingface/transformers
          cd transformers
          git rev-parse --short HEAD
          python -m pip install .
          python -c "import torch; print('torch:', torch.__version__, torch)"

      - name: Install deepspeed
        run: |
          python3 -m pip install docutils==0.18.1 jinja2==3.0 urllib3==1.26.11 ninja
          python3 -m pip install .[dev,1bit,autotuning]
          python3 -c "import torch; print('torch:', torch.__version__, torch)"
          ./bin/ds_report

      - name: Python environment
        run: |
          python3 -m pip list

      - name: Unit tests
        run: |
          unset TORCH_CUDA_ARCH_LIST # only jit compile for current arch
          if [[ -d ./torch-extensions ]]; then rm -rf ./torch-extensions; fi
          cd tests
          TORCH_EXTENSIONS_DIR=./torch-extensions python3 -m pytest --forked -n 4  unit/ --torch_ver="2.0" --cuda_ver="11"
          TORCH_EXTENSIONS_DIR=./torch-extensions python3 -m pytest --forked -m 'sequential' unit/ --torch_ver="2.0" --cuda_ver="11"
